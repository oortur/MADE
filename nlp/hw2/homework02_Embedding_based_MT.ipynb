{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "homework02_Embedding_based_MT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eulvfJWl7ueY"
      },
      "source": [
        "## Homework 02: Unsupervised embedding-based MT\n",
        "*Note: this homework is based on open materials from yandexdataschool [NLP course](https://github.com/yandexdataschool/nlp_course/). Feel free to check this awesome course if you wish to dig deeper.*\n",
        "\n",
        "*Refined by [Nikolay Karpachev](https://www.linkedin.com/in/nikolay-karpachev-b0146a104/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV4rIjxa7uei"
      },
      "source": [
        "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages, e.g. Ukrainian and Russian. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idSYq2GU7uew"
      },
      "source": [
        "### Frament of the Swadesh list for some slavic languages\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
        "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
        "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
        "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
        "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
        "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
        "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
        "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
        "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
        "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
        "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
        "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
        "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
        "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
        "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
        "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
        "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
        "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
        "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
        "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
        "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNM3_fjr7ue2"
      },
      "source": [
        "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLppwa527ue6"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYBGKAUn7ue_"
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwGoVhRA7ufP"
      },
      "source": [
        "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
        "\n",
        "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for Russian and Ukrainian languages. Please use word2vec-compatible format (.text)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tK9ESqBoP2B",
        "outputId": "39d0276e-80d7-4aa6-cce8-da7cbce5510c"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gunzip cc.ru.300.vec.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 14:18:26--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  13.1MB/s    in 96s     \n",
            "\n",
            "2021-04-18 14:20:02 (13.0 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otd_8TQWr4Ig",
        "outputId": "a229b3a1-5f8e-4c57-b5d3-3f85501076ab"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
        "!gunzip cc.uk.300.vec.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 14:23:31--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1257595219 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.uk.300.vec.gz’\n",
            "\n",
            "cc.uk.300.vec.gz      0%[                    ]  10.29M  7.95MB/s               ^C\n",
            "gzip: cc.uk.300.vec already exists; do you wish to overwrite (y or n)? ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ocr0coAqVgW"
      },
      "source": [
        "# !wget -qO- https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz | gunzip -c > cc.ru.300.vec"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1JjQv_97ufT",
        "outputId": "806e46f2-c152-4641-fe8b-4c6d42bb67f6"
      },
      "source": [
        "%%time\n",
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9min 3s, sys: 21.7 s, total: 9min 25s\n",
            "Wall time: 9min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffzuept_7ufd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880482bd-e8fb-4c37-8132-fc58635a2f9d"
      },
      "source": [
        "%%time\n",
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9min 8s, sys: 18.7 s, total: 9min 27s\n",
            "Wall time: 9min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTkXfT0W7ufk",
        "outputId": "90291a12-be18-4e44-a222-5b989dc58263"
      },
      "source": [
        "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0),\n",
              " ('июль', 0.9383153915405273),\n",
              " ('сентябрь', 0.9240028858184814),\n",
              " ('июнь', 0.9222575426101685),\n",
              " ('октябрь', 0.9095538854598999),\n",
              " ('ноябрь', 0.8930036425590515),\n",
              " ('апрель', 0.8729087114334106),\n",
              " ('декабрь', 0.8652557730674744),\n",
              " ('март', 0.8545796275138855),\n",
              " ('февраль', 0.8401416540145874)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdBA8lcg7ufs",
        "outputId": "1c8f3cec-f808-4f7e-e16f-961acc228dd2"
      },
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('серпень', 0.9999999403953552),\n",
              " ('липень', 0.9096440076828003),\n",
              " ('вересень', 0.901697039604187),\n",
              " ('червень', 0.8992519378662109),\n",
              " ('жовтень', 0.8810408711433411),\n",
              " ('листопад', 0.8787633776664734),\n",
              " ('квітень', 0.8592804670333862),\n",
              " ('грудень', 0.8586863279342651),\n",
              " ('травень', 0.8408110737800598),\n",
              " ('лютий', 0.8256431818008423)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yJvcKXO7uf0",
        "outputId": "7396991b-4bbc-4841-b1aa-7e90f4cf0bc0"
      },
      "source": [
        "ru_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Stepashka.com', 0.2757962942123413),\n",
              " ('ЖИЗНИВадим', 0.25203436613082886),\n",
              " ('2Дмитрий', 0.25048112869262695),\n",
              " ('2012Дмитрий', 0.24829231202602386),\n",
              " ('Ведущий-Алексей', 0.2443869560956955),\n",
              " ('Недопустимость', 0.24435284733772278),\n",
              " ('2Михаил', 0.23981399834156036),\n",
              " ('лексей', 0.23740756511688232),\n",
              " ('комплексн', 0.23695150017738342),\n",
              " ('персональ', 0.2368222028017044)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdYAR1q7uf6"
      },
      "source": [
        "Load small dictionaries for correspoinding words pairs as trainset and testset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35d_DAK67uf8"
      },
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkNL602WHJyO",
        "outputId": "365c321a-4a96-49c7-85d7-543422399f57"
      },
      "source": [
        "!wget -O ukr_rus.train.txt http://tiny.cc/jfgecz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 14:49:37--  http://tiny.cc/jfgecz\n",
            "Resolving tiny.cc (tiny.cc)... 157.245.113.153\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://tiny.cc/jfgecz [following]\n",
            "--2021-04-18 14:49:38--  https://tiny.cc/jfgecz\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt [following]\n",
            "--2021-04-18 14:49:38--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59351 (58K) [text/plain]\n",
            "Saving to: ‘ukr_rus.train.txt’\n",
            "\n",
            "ukr_rus.train.txt   100%[===================>]  57.96K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-04-18 14:49:39 (4.66 MB/s) - ‘ukr_rus.train.txt’ saved [59351/59351]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoclU6JcHCcn",
        "outputId": "ce2d7fa9-8615-4820-9a55-6ac4f39c7e4a"
      },
      "source": [
        "!wget -O ukr_rus.test.txt http://tiny.cc/6zoeez"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 14:49:45--  http://tiny.cc/6zoeez\n",
            "Resolving tiny.cc (tiny.cc)... 157.245.113.153\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://tiny.cc/6zoeez [following]\n",
            "--2021-04-18 14:49:46--  https://tiny.cc/6zoeez\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt [following]\n",
            "--2021-04-18 14:49:47--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12188 (12K) [text/plain]\n",
            "Saving to: ‘ukr_rus.test.txt’\n",
            "\n",
            "ukr_rus.test.txt    100%[===================>]  11.90K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-18 14:49:47 (26.3 MB/s) - ‘ukr_rus.test.txt’ saved [12188/12188]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05BqsdSK7ugD"
      },
      "source": [
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQOZw51r7ugL"
      },
      "source": [
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZBBNvpz7ugQ"
      },
      "source": [
        "## Embedding space mapping (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Dhk5gL7ugS"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
        "or\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
        "\n",
        "where $||*||_F$ - Frobenius norm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acOjDdtL7ugY"
      },
      "source": [
        "$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb-KN1be7uga",
        "outputId": "6d126db4-ab51-4d50-deb2-55df8f6b86b5"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# YOUR CODE HERE\n",
        "mapping = LinearRegression(fit_intercept=False)\n",
        "mapping.fit(X_train, Y_train)\n",
        "# -------"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7tqJwoY7ugf"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31SrFSbn7ugi",
        "outputId": "507f22de-69f9-4c9d-b84f-14682c974cc7"
      },
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8531432747840881),\n",
              " ('июнь', 0.8402522802352905),\n",
              " ('март', 0.8385884165763855),\n",
              " ('сентябрь', 0.8331484794616699),\n",
              " ('февраль', 0.8311208486557007),\n",
              " ('октябрь', 0.8278019428253174),\n",
              " ('ноябрь', 0.8243728280067444),\n",
              " ('июль', 0.8229618072509766),\n",
              " ('август', 0.8112280368804932),\n",
              " ('январь', 0.8022986650466919)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSkjk597ugo"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uY6Y9B7ugt"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zptuho8LAfIE"
      },
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "\n",
        "    for (_, ru), vector in zip(pairs, mapped_vectors):\n",
        "        top_words = [word for word, _ in ru_emb.most_similar(vector.reshape(1, -1), topn=topn)]\n",
        "        if ru in top_words:\n",
        "            num_matches += 1\n",
        "\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duhj9hpv7ugy"
      },
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-iyd5gP7ug5",
        "outputId": "a4366a91-b0b4-42b8-9257-517c16c379d9"
      },
      "source": [
        "%%time\n",
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 44s, sys: 58.9 s, total: 6min 43s\n",
            "Wall time: 1min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ssEJ3x7uhA",
        "outputId": "d0852494-22d3-4b50-8f58-c747d1c6b52e"
      },
      "source": [
        "%%time\n",
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 54s, sys: 1min 12s, total: 7min 6s\n",
            "Wall time: 1min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K-hy7a6Ksn2",
        "outputId": "5d259c64-de0f-4ac2-f3ee-47c3cb82a622"
      },
      "source": [
        "print(precision_top1)\n",
        "print(precision_top5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.628498727735369\n",
            "0.7913486005089059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf6Ou8bx7uhH"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem) (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oLs-drN7uhK"
      },
      "source": [
        "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$W^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KSaRJFGMFiJ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdFQ7qti7uhL"
      },
      "source": [
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\" \n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    # YOUR CODE GOES HERE\n",
        "    # compute orthogonal embedding space mapping\n",
        "    u, s, vh = np.linalg.svd(X_train.T @ Y_train)\n",
        "    mapping = u @ vh\n",
        "\n",
        "    return mapping"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7QfYDd7uhQ"
      },
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVOFYYa37uhX",
        "outputId": "f8a28d4b-3e81-48de-8c94-0218779f5bcd"
      },
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8245131969451904),\n",
              " ('июнь', 0.805662989616394),\n",
              " ('сентябрь', 0.8055761456489563),\n",
              " ('март', 0.8032935261726379),\n",
              " ('октябрь', 0.7987102270126343),\n",
              " ('июль', 0.7946797013282776),\n",
              " ('ноябрь', 0.7939636707305908),\n",
              " ('август', 0.7938188910484314),\n",
              " ('февраль', 0.7923861145973206),\n",
              " ('декабрь', 0.7715375423431396)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r297sYP37uhb",
        "outputId": "82f3bf53-6b37-4f6e-bd70-a08feefbd589"
      },
      "source": [
        "%%time\n",
        "print(precision(uk_ru_test, np.matmul(X_test, W)))\n",
        "print(precision(uk_ru_test, np.matmul(X_test, W), 5))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6437659033078881\n",
            "0.7989821882951654\n",
            "CPU times: user 5min 53s, sys: 1min 12s, total: 7min 6s\n",
            "Wall time: 1min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvUZ72U5AfJg"
      },
      "source": [
        "## Unsupervised embedding-based MT (0.4 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyuVfHBLrJn"
      },
      "source": [
        "Now, let's build our word embeddings-based translator!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPAURW1CMuP7"
      },
      "source": [
        "Firstly, download OPUS Tatoeba corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F80kUKzQMsDu",
        "outputId": "a4b10901-d3b3-4c5e-d922-1027ab87d372"
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 14:57:03--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1819128 (1.7M) [application/gzip]\n",
            "Saving to: ‘uk.txt.gz’\n",
            "\n",
            "uk.txt.gz           100%[===================>]   1.73M   904KB/s    in 2.0s    \n",
            "\n",
            "2021-04-18 14:57:07 (904 KB/s) - ‘uk.txt.gz’ saved [1819128/1819128]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CGFZoxCUVf1"
      },
      "source": [
        "!gzip -d ./uk.txt.gz"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MV3VvoVUX5U"
      },
      "source": [
        "with open('./uk.txt', 'r') as f:\n",
        "    uk_corpus = f.readlines()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU7nPVf0UhbI"
      },
      "source": [
        "# To save your time and CPU, feel free to use first 1000 sentences of the corpus\n",
        "uk_corpus = uk_corpus[:1000]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLN8dBOXAfJ1"
      },
      "source": [
        "# Any necessary preprocessing if needed\n",
        "\n",
        "# We may try both to apply converting words to lowercase or not \n",
        "\n",
        "# uk_corpus = [text.lower() for text in uk_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGksC7l_NMi9"
      },
      "source": [
        "import re\n",
        "\n",
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    # YOUR CODE GOES HERE\n",
        "    translated = []\n",
        "    for token in sentence.split():\n",
        "\n",
        "        # to deal with cases <token> = <word><punctuation>, split it into informative <word> and keep <punctuation>\n",
        "        punct = ''\n",
        "        if len(token) > 1 and token[-1].isalpha() == False:\n",
        "            punct = token[-1]\n",
        "            token = token[:-1]\n",
        "\n",
        "        # to deal with cases when <token> contains punctuation\n",
        "        # EXAMPLE: сім’я = семья\n",
        "        token = token if len(token) == 1 else ''.join(re.findall('\\w+', token))\n",
        "\n",
        "        try:\n",
        "            vector = uk_emb.get_vector(token)\n",
        "            translated_token = ru_emb.most_similar([np.matmul(vector, W)])[0][0]\n",
        "        except KeyError:\n",
        "            translated_token = \"<UNK>\"\n",
        "        translated.append(translated_token + punct)\n",
        "\n",
        "    return \" \".join(translated)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hbbMy-tNxlf"
      },
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia6I2ce7O_HI"
      },
      "source": [
        "Now you can play with your model and try to get as accurate translations as possible. **Note**: one big issue is out-of-vocabulary words. Try to think of various ways of handling it (you can start with translating each of them to a special **UNK** token and then move to more sophisticated approaches). Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap1W7ZCeOAVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e778c95c-9f28-4da5-8604-b938f2acac55"
      },
      "source": [
        "for sent in uk_corpus[::10]:\n",
        "    print(translate(sent))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Я уже закончу колледж, когда мы прибежишь со Америки.\n",
            "Город бомбили враждебные самолеты.\n",
            "Возможно, мной антисоциальный, конечно это не означает, что мной не общаюсь со людьми.\n",
            "Впрочем утра выпала роса.\n",
            "Беда не приходит одна.\n",
            "Посмотри по тот дым.\n",
            "Я заказал два гамбургера.\n",
            "Я не хотел никого обидеть.\n",
            "Гора покрыта снегом.\n",
            "по фотографии во девушки корона не со золота, а со цветов.\n",
            "Во меня То мечта.\n",
            "Я приехал во Японию со Китая.\n",
            "по север находится Шотландия; по юге — Англия; по востоке — Уэльс; и ещe дальше по востоке — северная Ирландия.\n",
            "Его родная страна — Германия.\n",
            "Берн — столица Швейцарии.\n",
            "Он ждал по него к десятой часа.\n",
            "Ты можешь взять ту книгу даром.\n",
            "Такой роман сочинил известный американский писатель.\n",
            "забронировать, будте ласковые, комнату возле международного аэропорта во Торонто.\n",
            "Он знает, что ты его влюбится?\n",
            "Я знаю, что ты богатый.\n",
            "Те, кто всё забывают, счастливые.\n",
            "Во этой реке опасно плавать.\n",
            "пришел, увидел, победил.\n",
            "Я хожу к школы пешком.\n",
            "Не моя дело!\n",
            "Не забудь билет.\n",
            "Кто он?\n",
            "Вы будете чай ли кофе?\n",
            "Он не пойдет по пикник, как и мной.\n",
            "Когда Вы родились?\n",
            "Это моя любимая песня.\n",
            "мы почти семья.\n",
            "Какой красивый сегодня месяц!\n",
            "Я против любых войны.\n",
            "поверхность воздушной шары — <UNK> пространство, потому для неё не выполняются правила симметрической геометрии.\n",
            "Говорят, что американцы считают количество денег, какую зарабатывает женщина, мерилом его умение.\n",
            "Можно мной <UNK> это платье?\n",
            "Если будет красивая погода, мы доберёмся туда завтра.\n",
            "Это был злой заяц.\n",
            "Один, два, три, четыре, пять-, восемь, семь, восемь, семдесят, десять.\n",
            "Кто во любви не знает, тот горя не знает.\n",
            "Его иметь волнуется за него.\n",
            "Я уважаю тех, кто старается со всех сил.\n",
            "необычайная дружба переросла во глубокое любовь.\n",
            "Рейчел пёт много молока каждый день.\n",
            "Он вор.\n",
            "<UNK> загрязнение можно было бы <UNK> только если бы люди были более чувствительны к окружающей среды.\n",
            "чай со лимоном, будте ласковые.\n",
            "Не путать желание со влюбленностью.\n",
            "Я бы со удовольствием сочинил сотни сложноподчинённые во <UNK>, конечно во меня То дела.\n",
            "Дайте мне чашечку кофе.\n",
            "ведь же ты никогда мне о это не рассказывала!\n",
            "Во тебя будут проблемы, если твои родители узнают.\n",
            "Запах роз наполнил комнату.\n",
            "Как во тебя дела?\n",
            "Это мои штаны.\n",
            "НЕт, спасибо.\n",
            "Я не понимаю, почему Германия победила по Евровидении.\n",
            "Добрый вечер.\n",
            "Со <UNK> Алексея Палашка поприветствовал президент Белоруссии Александр Лукашенко.\n",
            "Млечный путь — широкий пояс со далеких звёзд, каждая звезда — солнце, такое как наше.\n",
            "удивительно видеть <UNK> со галстук!\n",
            "всё печенье во форме звёзд.\n",
            "ЧТо мне одеть — штаны ли юбку?\n",
            "Краусс утверждал — известный московский скульптор.\n",
            "Ой был злой кролик.\n",
            "Можешь взять любой, что тебе к отвратиться.\n",
            "Конечно мной пойду.\n",
            "шелковичные прядут коконы.\n",
            "ЧТо бы ты сделала, если бы во тебя было, замечу, десять тысяч долларов?\n",
            "Он думает, что он кто-то, а действительно он никто.\n",
            "она очень гордится своею коллекцией марок.\n",
            "Он очень простой.\n",
            "Какая ты добра!\n",
            "Как мной за тобой соскучился!\n",
            "Это всё, что мной знаю.\n",
            "Ты ведёшь дневник?\n",
            "Тебе решать.\n",
            "Это почта, а то — банк.\n",
            "Это всё, что мной хочу сделать.\n",
            "Я впервые смотрю такой страшный фильм.\n",
            "Этa песня напоминает мне о дом.\n",
            "Хироси здесь?\n",
            "Меня зовут Эдди.\n",
            "Как женщина живет, так она и умрет.\n",
            "Я здесь уже две часа.\n",
            "Мне надо извиниться перед Нб.\n",
            "Сегодня мной видел скворца.\n",
            "Сколько стоить та носовая косыночка» — наверное пять- центов.\n",
            "солдаты медведи, как правило, очень опасные.\n",
            "Он быстро устает.\n",
            "остальные готовы.\n",
            "Он скучает по своей семьи.\n",
            "Спасибо, — по здоровье.\n",
            "Я ещe не знаю своего адреса, мной определенный момент буду жить во подруги.\n",
            "Амазонка— вторая по длине река во мире после Нила.\n",
            "А если увидишь Тима, передай ему от меня поздравления.\n",
            "закрой за собой дверь.\n",
            "Держи при себе словарь.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMlIUCfJhe9g"
      },
      "source": [
        "Proper processing of sentence during translation helped to catch all words from vocabulary and to decrease number of possible mistakes. \\<UNK\\> token was used for out-of-vocabulary words.\n",
        "\n",
        "Below you may see few examples of both original and translated text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rS2zNL4jE9X",
        "outputId": "e417f6b9-2e54-4574-cda8-f045dc9bb494"
      },
      "source": [
        "for sent in uk_corpus[::30]:\n",
        "    print(f\"Original text: {sent}Translated text: {translate(sent)}\\n\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: Я вже закінчу коледж, коли ви вернетеся з Америки.\n",
            "Translated text: Я уже закончу колледж, когда мы прибежишь со Америки.\n",
            "\n",
            "Original text: Цього ранку випала роса.\n",
            "Translated text: Впрочем утра выпала роса.\n",
            "\n",
            "Original text: Я замовив два гамбургера.\n",
            "Translated text: Я заказал два гамбургера.\n",
            "\n",
            "Original text: На фотографії в дівчини корона не з золота, а з квітів.\n",
            "Translated text: по фотографии во девушки корона не со золота, а со цветов.\n",
            "\n",
            "Original text: На півночі знаходиться Шотландія; на півдні — Англія; на заході — Уельс; і ще далі на заході — Північна Ірландія.\n",
            "Translated text: по север находится Шотландия; по юге — Англия; по востоке — Уэльс; и ещe дальше по востоке — северная Ирландия.\n",
            "\n",
            "Original text: Він чекав на нього до десятої години.\n",
            "Translated text: Он ждал по него к десятой часа.\n",
            "\n",
            "Original text: Забронюйте, будьте ласкаві, кімнату біля міжнародного аеропорту в Торонто.\n",
            "Translated text: забронировать, будте ласковые, комнату возле международного аэропорта во Торонто.\n",
            "\n",
            "Original text: Ті, хто все забувають, щасливі.\n",
            "Translated text: Те, кто всё забывают, счастливые.\n",
            "\n",
            "Original text: Я ходжу до школи пішки.\n",
            "Translated text: Я хожу к школы пешком.\n",
            "\n",
            "Original text: Хто він?\n",
            "Translated text: Кто он?\n",
            "\n",
            "Original text: Коли Ви народилися?\n",
            "Translated text: Когда Вы родились?\n",
            "\n",
            "Original text: Який гарний сьогодні місяць!\n",
            "Translated text: Какой красивый сегодня месяц!\n",
            "\n",
            "Original text: Кажуть, що американці вважають кількість грошей, яку заробляє людина, мірилом його уміння.\n",
            "Translated text: Говорят, что американцы считают количество денег, какую зарабатывает женщина, мерилом его умение.\n",
            "\n",
            "Original text: Це був злий заєць.\n",
            "Translated text: Это был злой заяц.\n",
            "\n",
            "Original text: Його мати хвилюється за нього.\n",
            "Translated text: Его иметь волнуется за него.\n",
            "\n",
            "Original text: Кейт п’є багато молока кожен день.\n",
            "Translated text: Рейчел пёт много молока каждый день.\n",
            "\n",
            "Original text: Чай з лимоном, будьте ласкаві.\n",
            "Translated text: чай со лимоном, будте ласковые.\n",
            "\n",
            "Original text: Дайте мені філіжанку кави.\n",
            "Translated text: Дайте мне чашечку кофе.\n",
            "\n",
            "Original text: Запах троянд наповнив кімнату.\n",
            "Translated text: Запах роз наполнил комнату.\n",
            "\n",
            "Original text: Ні, дякую.\n",
            "Translated text: НЕт, спасибо.\n",
            "\n",
            "Original text: З юбілеєм Олексія Дударева привітав Президент Білорусі Олександр Лукашенко.\n",
            "Translated text: Со <UNK> Алексея Палашка поприветствовал президент Белоруссии Александр Лукашенко.\n",
            "\n",
            "Original text: Усе печиво у формі зірок.\n",
            "Translated text: всё печенье во форме звёзд.\n",
            "\n",
            "Original text: То був злий кролик.\n",
            "Translated text: Ой был злой кролик.\n",
            "\n",
            "Original text: Шовкопряди прядуть кокони.\n",
            "Translated text: шелковичные прядут коконы.\n",
            "\n",
            "Original text: Вона дуже пишається своєю колекцією марок.\n",
            "Translated text: она очень гордится своею коллекцией марок.\n",
            "\n",
            "Original text: Як я за тобою скучив!\n",
            "Translated text: Как мной за тобой соскучился!\n",
            "\n",
            "Original text: Тобі вирішувати.\n",
            "Translated text: Тебе решать.\n",
            "\n",
            "Original text: Я вперше дивлюся такий страшний фільм.\n",
            "Translated text: Я впервые смотрю такой страшный фильм.\n",
            "\n",
            "Original text: Мене звуть Джек.\n",
            "Translated text: Меня зовут Эдди.\n",
            "\n",
            "Original text: Мені треба вибачитись перед Ен.\n",
            "Translated text: Мне надо извиниться перед Нб.\n",
            "\n",
            "Original text: Ранені ведмеді, як правило, дуже небезпечні.\n",
            "Translated text: солдаты медведи, как правило, очень опасные.\n",
            "\n",
            "Original text: Він скучає по своїй сім'ї.\n",
            "Translated text: Он скучает по своей семьи.\n",
            "\n",
            "Original text: Амазонка— друга по довжині ріка в світі після Ніла.\n",
            "Translated text: Амазонка— вторая по длине река во мире после Нила.\n",
            "\n",
            "Original text: Тримай при собі словник.\n",
            "Translated text: Держи при себе словарь.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZklXyoXj-Wo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}